{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tools.models import AE\n",
    "from tools.loadData import DataSets\n",
    "from tensorflow.keras import optimizers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "batch_size=128\n",
    "classes=10\n",
    "batch_size=256\n",
    "him_dims=20\n",
    "dataset_name='mnist'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**load fashionMnist Data**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 28, 28) (256, 10)\n"
     ]
    }
   ],
   "source": [
    "datasets=DataSets()\n",
    "train_db,val_db,test_db=datasets.load_data(dataset_name,batch_size,classes)\n",
    "x,y=next(iter(train_db))\n",
    "print(x.shape,y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**load model**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ae_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_14 (Sequential)   (None, 128)               566144    \n",
      "_________________________________________________________________\n",
      "sequential_15 (Sequential)   (None, 784)               566800    \n",
      "=================================================================\n",
      "Total params: 1,132,944\n",
      "Trainable params: 1,132,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=AE(128)\n",
    "model.build(input_shape=(None,28*28))\n",
    "model.summary()\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = r'E:/pythonProject/DeepLearning/resources/logs/auto_encoding/' + current_time\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "\n",
    "def save_img(imgs,name):\n",
    "    new_img=Image.new('L',(280,280))\n",
    "    index=0\n",
    "    for i in range(0,280,28):\n",
    "        for j in range(0,280,28):\n",
    "            im=imgs[index]\n",
    "            im=Image.fromarray(im,mode='L')\n",
    "            new_img.paste(im,(i,j))\n",
    "            index+=1\n",
    "    new_img.save(name)\n",
    "    return new_img\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**trainModel**\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=0,loss=0.69\n",
      "step=100,loss=0.16\n",
      "step=0,loss=0.12\n",
      "step=100,loss=0.10\n",
      "step=0,loss=0.10\n",
      "step=100,loss=0.09\n",
      "step=0,loss=0.09\n",
      "step=100,loss=0.09\n",
      "step=0,loss=0.09\n",
      "step=100,loss=0.08\n",
      "step=0,loss=0.08\n",
      "step=100,loss=0.08\n",
      "step=0,loss=0.08\n",
      "step=100,loss=0.08\n",
      "step=0,loss=0.08\n",
      "step=100,loss=0.08\n",
      "step=0,loss=0.07\n",
      "step=100,loss=0.08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-48-18f3ce6ad3c5>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     11\u001B[0m             \u001B[0mtotal_step\u001B[0m\u001B[1;33m+=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0msummary_writer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mas_default\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m                 \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msummary\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscalar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"train_loss\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtotal_step\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[0mgrads\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgradient\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\python\\anaconda3\\lib\\contextlib.py\u001B[0m in \u001B[0;36m__exit__\u001B[1;34m(self, type, value, traceback)\u001B[0m\n\u001B[0;32m    118\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mtype\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    119\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 120\u001B[1;33m                 \u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgen\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    121\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    122\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\python\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py\u001B[0m in \u001B[0;36mas_default\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    267\u001B[0m       \u001B[1;31m# Flushes the summary writer in eager mode or in graph functions, but\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    268\u001B[0m       \u001B[1;31m# not in legacy graph mode (you're on your own there).\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 269\u001B[1;33m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflush\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    270\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    271\u001B[0m       \u001B[0m_summary_state\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwriter\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mold\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\python\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py\u001B[0m in \u001B[0;36mflush\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    284\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_v2\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_closed\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    285\u001B[0m       \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 286\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_flush_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwriter\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    287\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    288\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\python\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py\u001B[0m in \u001B[0;36mflush\u001B[1;34m(writer, name)\u001B[0m\n\u001B[0;32m    965\u001B[0m     \u001B[0mresource\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mwriter\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    966\u001B[0m   \u001B[1;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"cpu:0\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 967\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mgen_summary_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflush_summary_writer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresource\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    968\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    969\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mH:\\python\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_summary_ops.py\u001B[0m in \u001B[0;36mflush_summary_writer\u001B[1;34m(writer, name)\u001B[0m\n\u001B[0;32m    194\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mtld\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_eager\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    195\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 196\u001B[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001B[0m\u001B[0;32m    197\u001B[0m         \u001B[0m_ctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_context_handle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtld\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"FlushSummaryWriter\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    198\u001B[0m         tld.op_callbacks, writer)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "optimizer=optimizers.Adam(lr=lr)\n",
    "\n",
    "total_step=0\n",
    "for epoch in range(50):\n",
    "    for step, (x,y) in enumerate(train_db):\n",
    "        with tf.GradientTape() as tape:\n",
    "            x=tf.reshape(x,[-1,784])\n",
    "            logits=model(x)\n",
    "            loss=tf.losses.binary_crossentropy(x,logits,from_logits=True)\n",
    "            loss=tf.reduce_mean(loss)\n",
    "            total_step+=1\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar(\"train_loss\",loss,total_step)\n",
    "\n",
    "        grads=tape.gradient(loss,model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "\n",
    "        if step%100==0:\n",
    "            print(\"step=%d,loss=%0.2f\"%(step,float(loss)))\n",
    "\n",
    "    # 每次epoch 显示图片\n",
    "    # predict\n",
    "    x,y=next(iter(test_db))\n",
    "    logit=model(tf.reshape(x,[-1,784]))\n",
    "    x_hat=tf.sigmoid(logit)\n",
    "\n",
    "    x_hat=tf.reshape(x_hat,[-1,28,28])\n",
    "\n",
    "    x_concat=tf.concat([x[:50],x_hat[:50]],axis=0)\n",
    "    x_concat=x_concat.numpy()*255\n",
    "    x_concat=x_concat.astype(np.uint8)\n",
    "\n",
    "    # saveimage\n",
    "    new_img=save_img(x_concat,os.path.join(r\"E:\\pythonProject\\DeepLearning\\resources\\images\\autoEncode_img\",\n",
    "                                           dataset_name,\n",
    "                                           \"epoch_%d.png\"%epoch\n",
    "                                           ))\n",
    "    new_img=np.asarray(new_img)\n",
    "    new_img=np.expand_dims(new_img,[0,3])\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.image(\"第%d个epoch的编码图\"%(epoch+1),new_img,epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-368948a5",
   "language": "python",
   "display_name": "PyCharm (opencv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}